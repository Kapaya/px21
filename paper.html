<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <link href="https://fonts.googleapis.com/css?family=Merriweather:300,700" rel="stylesheet">
  <meta name="author" content="Kapaya Katongo, Geoffrey Litt and Daniel Jackson" />
  <title>Towards End-user Web Scraping For Customization</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="basic.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>

<header id="title-block-header">
<h1 class="title">Towards End-user Web Scraping For Customization</h1>
<p class="author">By Kapaya Katongo, <a href="https://www.geoffreylitt.com/">Geoffrey Litt</a> and <a href="http://people.csail.mit.edu/dnj/">Daniel Jackson</a></p>
<p class="date">This paper will be submitted to the <a href="https://2021.programming-conference.org/home/px-2021">PX/21</a> workshop. Also available in a <a href="paper.pdf">PDF version</a>.</p>
</header>
<p>Websites are malleable: users can install browser extensions and run arbitrary Javascript in the developer console to change them. However, this malleability is only accessible to programmers with knowledge of HTML, CSS, Javascript and the DOM. To broaden access to customization, our prior work developed an approach that empowers end-users to customize websites without traditional programming via a browser extension called Wildcard.</p>
<p>Wildcard’s customizations are powered by web scraping adapters which are currently written in Javascript by programmers. This means that end-users can only customize a website if a programmer has written an adapter for it. Furthermore, end-users do not have the ability to extend adapters in order to perform new customizations or repair adapters to fix broken customizations.</p>
<p>In this paper, we present our progress towards extending Wildcard to empower end-users to create, extend and repair adapters by demonstration. We describe three design principles that guided our system’s development and are applicable to other end-user web scraping and customization system: (a) users should be able to scrape data and use it in a single environment, (b) users should be able to extend and repair the programs that scrape data via demonstration and (b) users should receive live feedback during their demonstrations.</p>
<p>We have succesfully used our system to create, extend and repair adapters by demonstration on a variety of websites and provide example usage scenarios that showcase each of our design principles.</p>
<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Contents</h2>
<ul>
<li><a href="#sec:introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#sec:demos"><span class="toc-section-number">2</span> Motivating Examples</a></li>
<li><a href="#sec:implementation"><span class="toc-section-number">3</span> System Implementation</a></li>
<li><a href="#sec:design-principles"><span class="toc-section-number">4</span> Design Principles</a></li>
<li><a href="#sec:related-work"><span class="toc-section-number">5</span> Related Work</a></li>
<li><a href="#sec:conclusion"><span class="toc-section-number">6</span> Conclusion And Future Work</a></li>
<li><a href="#bibliography">References</a></li>
</ul>
</nav>
<h1 data-number="1" id="sec:introduction"><span class="header-section-number">1</span> Introduction</h1>
<p>Many websites on the internet do not meet the exact needs of all of their users. End-user web customization systems like Chickenfoot <span class="citation" data-cites="bolin2005">[<a href="#ref-bolin2005" role="doc-biblioref">3</a>]</span>, Thresher <span class="citation" data-cites="hogue2005">[<a href="#ref-hogue2005" role="doc-biblioref">6</a>]</span>, Sifter <span class="citation" data-cites="huynh2006">[<a href="#ref-huynh2006" role="doc-biblioref">7</a>]</span> and Vegemite [lin2009] help users tweak and adapt websites to fit their unique requirements, ranging from reorganizing or annotating content on the website to automating common tasks. In our prior work, we presented Wildcard <span class="citation" data-cites="litt2020a">[<a href="#ref-litt2020a" role="doc-biblioref">12</a>]</span>, a customization system which enables end-users to customize websites through direct manipulation. It does this by augmenting websites with a table view that shows their underlying structured data. The table is bidirectionally synchronized with the original website, so end-users can easily customize the website by interacting with the table, including sorting and filtering data, adding annotations, and running computations in a spreadsheet formula language.</p>
<p>Wildcard has a key limitation. In order to enable end-users to customize a website, a Javascript programmer first needs to code an adapter that specifies how to scrape the website content and set up a bidirectional synchronization with Wildcard’s table view. Take Alice, an end-user that uses Wildcard to customize her experience on Google Scholar. Wildcard’s sorting customization gives her the power to sort publications by title which the website does not natively allow. She thinks this will be useful on Weather.com to sort the ten day forecast by the weather descriptions so that she can quickly find all the sunny days. Unfortunately, a programmer has not coded an adapter for Weather.com so Alice is unable to customize it. Additionally, if the adapter for timeanddate.com, which she uses to sort the list of holidays in a year, does not scrape all the data she wats, or the adapter for Google Scholar stops functioning when the website changes, Alice has no recourse to extend or repair them on her own.</p>
<p>In this paper, we describe an addition to Wildcard: a system that enables end-users to create, extend and repair website adapters by demonstration within the browser. Using this scraping system, an end-user can perform end-to-end web customizations using Wildcard on arbitrary websites, without ever needing to code an adapter. Through a series of examples, we show that end-users can utilize our system to successfully create Wildcard adapters on a variety of websites via demonstration (Section 2). We also describe key aspects of our system and how web scraping for customization reveals a constraint that simplifies the <em>wrapper induction</em> <span class="citation" data-cites="kushmerick2000">[<a href="#ref-kushmerick2000" role="doc-biblioref">8</a>]</span> task used to generalize user demonstrations (Section 3).</p>
<p>Our key contribution is a set of three design principles that guided the design of our system, which also offer insights that might be applied to other end-user web scraping and customization tools (Section 4):</p>
<ul>
<li><strong>Unified Environment</strong>: Users should be able to scrape data and interact with the scraped data in a single environment. This minimizes the barrier to fluidly switching back and forth between the two tasks, rather than treating them as entirely independent tasks.</li>
<li><strong>Editing By Demonstration</strong>: Users should be able to not only create programs for scraping data by demonstration, but also extend and repair the programs by demonstration. This enables users to build on other user’s work, and is especially important in the context of web scraping since programs that scrape data sometimes break as the underlying website changes.</li>
<li><strong>Live Programming</strong>: Users should receive live feedback as they perform demonstrations. The system should indicate how it is generalizing from the user’s example and what the resulting data will look like, so that the user can adjust their demonstrations on the fly and quickly arrive at the desired result.</li>
</ul>
<p>Finally, we share our broader vision for web scraping for customization, and some opportunities for future work, including a proposal for how Wildcard’s spreadsheet-like formula language might augment demonstrations to provide end-users with more expressiveness in the web scraping process (Section 6).</p>
<h1 data-number="2" id="sec:demos"><span class="header-section-number">2</span> Motivating Examples</h1>
<p>In this section, we show how end-users can create, extend and repair adapters for Wildcard via demonstration.</p>
<h2 data-number="2.1" id="creating-an-adapter"><span class="header-section-number">2.1</span> Creating An Adapter</h2>
<p>Alice, our end-user from Section 1, has heard that Wildcard now provides a way for none-programmers to create, extend and repair website adapters needed to enable customizations. This will allow her to customize her experience on Weather.com by sorting the ten-day forecast based on the description of the weather on each day, allowing her to easily view all the sunny days. She starts the adapter creation process by clicking a context menu item within the Weather.com page, and hovers over a data value she might like to scrape.</p>
<video controls="controls" muted="muted" src="media/2.1.1.mp4" muted playsinline controls class>
</video>
<p>The system provides live feedback as Alice hovers:</p>
<ul>
<li>The selected row of data is annotated in the page with a border, to indicate that she will be demonstrating values from within that row.</li>
<li>The selected column of data is highlighted in the page with a green background, to show how the system has generalized her demonstration across all the rows in the data.</li>
<li>A table view appears at the bottom of the screen, and displays how the values will appear in the data table.</li>
</ul>
<p>Alice tries hovering over several other elements in the page, taking advantage of the <strong>live programming</strong> environment to decide what data would be useful. After considering several options, she decides to save the date field in the first column of the table, and commits the action by clicking.</p>
<video controls="controls" muted="muted" src="media/2.1.2.mp4" muted playsinline controls class>
</video>
<p>Next, she performs a similar process to fill the next column with the weather descriptions. After filling both columns, she also tries hovering over previously scraped data, and the toolbar at the top of the page indicates which column corresponds to the previously scraped data. Finally, she ends the adapter creation process and is able to immediately sort the forecast by the weather description column because Wildcard provides a <strong>unified environment</strong> for scraping and customizing:</p>
<video controls="controls" muted="muted" src="media/2.1.3.mp4" muted playsinline controls class>
</video>
<h2 data-number="2.2" id="extending-an-adapter"><span class="header-section-number">2.2</span> Extending An Adapter</h2>
<p>Alice recalls that she also uses Wildcard to customize timeanddate.com. In addition to sorting the list of holidays in a year by the day of the week, she also wants to sort them by the type of holiday. This would let her view the all federal holidays together for example. Previously, she would have needed to find a programmer to help her edit the adapter code. Using our system, Alice can extend the adapter herself.</p>
<p>Once on timeanddate.com, she clicks the “Edit Scraper” button on top of Wildcard’s table to initiate the adapter editing process. As she hovers over the currently scraped values, the columns they belong to are highlighted. Finally, she clicks on “Federal Holiday” to add the new column of data and saves the changes. Alice then proceeds to sort the list by the type of holiday without the intervention of a programmer, a task made possible because of <strong>editing by demonstration</strong>.</p>
<video controls="controls" muted="muted" src="media/2.3.2.mp4" muted playsinline controls class>
</video>
<h2 data-number="2.3" id="repairing-an-adapter"><span class="header-section-number">2.3</span> Repairing An Adapter</h2>
<p>Having procrastinated enough, Alice returns to Google Scholar to look up references for her thesis project. Unfortunately, the customization she had applied to sort publications by their title (which is not natively supported by Google Scholar) is no longer working. In fact, the column in the Wildcard table that contained all the publication titles is empty. Unbeknownst to her, the website’s internals had changed as a result of a update.</p>
<p>To fix this, Alice initiates the editing process, and initially hovers over the desired value to demonstrate the column she wants to scrape. However, she notices that the values would be populated into column D; instead, she wants the values to be inserted into column A where they previously appeared. Alice clicks on the symbol for column A to indicate that he wants to scrape the values into that column. She then proceeds to re-apply her customization to the website by sorting the publications by their title without the intervention of a programmer, another task made possible because of <strong>editing by demonstration</strong>.</p>
<video controls="controls" muted="muted" src="media/2.4.2.mp4" muted playsinline controls class>
</video>
<h1 data-number="3" id="sec:implementation"><span class="header-section-number">3</span> System Implementation</h1>
<p>We implemented our end-user web scraping system as an addition to the Wildcard browser extension. We start by describing our implementations of row and column generalization, live programming and editing by demonstration and end by discussing some of the current limitations of our system.</p>
<h2 data-number="3.1" id="generalization-algorithms"><span class="header-section-number">3.1</span> Generalization Algorithms</h2>
<p>In order to generate reusable scrapers from user demonstrations, our system solves the <em>wrapper induction</em> <span class="citation" data-cites="kushmerick2000">[<a href="#ref-kushmerick2000" role="doc-biblioref">8</a>]</span> task: generalizing from a small set of user-provided examples to a scraping specification that will work on other parts of the website, and on future versions of the website.</p>
<p>We take an approach similar to that used in other tools like Vegemite <span class="citation" data-cites="lin2009">[<a href="#ref-lin2009" role="doc-biblioref">11</a>]</span> and Sifter <span class="citation" data-cites="huynh2006">[<a href="#ref-huynh2006" role="doc-biblioref">7</a>]</span>:</p>
<ul>
<li>We generate a single <em>row selector</em> for the website: a CSS selector that returns a set of DOM elements corresponding to individual rows of the table.</li>
<li>For each column in the table, we generate a <em>column selector</em>, a CSS selector that returns the element containing the column value within that row.</li>
</ul>
<p>One important difference is that our algorithm only accepts row elements that have direct siblings with a similar structure. We refer to this as the <em>row-sibling</em> constraint. Later in this section, we describe how the constraint provides a useful simplification of the wrapper induction task and discuss the resulting limitations this puts on our system in a section that follows.</p>
<p>When a user first demonstrates a column value, the generalization algorithm is responsible for turning the demonstration into a row selector that will correctly identify all the row elements in the website and a column selector that will correctly identify the element that contains the column value within a row element. During subsequent demonstrations, the generalization algorithm uses the generated row selector to find the row element that contains the column value and generates a column selector which identifies the corresponding column element.</p>
<p>At a high level, the generalization algorithm’s challenge is to traverse far enough up in the DOM tree from the demonstrated element to find the element which corresponds to the row. We solve this using a heuristic; the basic intuition is to find a large set of elements with similar parallel structure. Consider the following sample HTML layout, which displays a truncated table of superheroes, with each row containing some nested structure:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;h1&gt;</span> Team Iron Man <span class="kw">&lt;/h1&gt;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">’container’</span><span class="kw">&gt;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;avenger&#39;</span><span class="kw">&gt;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;names&#39;</span><span class="kw">&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span> Iron Man <span class="kw">&lt;/span&gt;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>                <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;real_name&#39;</span><span class="kw">&gt;</span> Tony Stark <span class="kw">&lt;/span&gt;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;/div&gt;</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>           <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">’gender’</span><span class="kw">&gt;</span> Male <span class="kw">&lt;/span&gt;</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;/div&gt;</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;avenger&#39;</span><span class="kw">&gt;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;names&#39;</span><span class="kw">&gt;</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span>  Black Widow <span class="kw">&lt;/span&gt;</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;real_name&#39;</span><span class="kw">&gt;</span> Natalia Romanoff <span class="kw">&lt;/span&gt;</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;/div&gt;</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">’gender’</span><span class="kw">&gt;</span> Female <span class="kw">&lt;/span&gt;</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;/div&gt;</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/div&gt;</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span></span></code></pre></div>
<p>The user performs a demonstration by clicking on the SPAN element containing “Tony Stark.” Our algorithm traverses upwards from the demonstrated element, considering each successive parent element as a potential candidate for the row element. For each parent element <span class="math inline"><em>n</em></span>, the process is as follows:</p>
<ol type="1">
<li>compute a selector <span class="math inline"><em>s</em></span> that when executed on <span class="math inline"><em>n</em></span> only returns the demonstrated element</li>
<li>for each sibling <span class="math inline"><em>m</em></span> of <span class="math inline"><em>n</em></span>, execute <span class="math inline"><em>s</em></span> on <span class="math inline"><em>m</em></span> and record whether the selector returned an element. Intuitively, if the selector returns an element, this suggests that the sibling <span class="math inline"><em>m</em></span> has some parallel structure to <span class="math inline"><em>n</em></span></li>
<li>compute <span class="math inline"><em>n</em><sub><em>s</em><em>i</em><em>b</em><em>l</em><em>i</em><em>n</em><em>g</em><em>s</em></sub></span>, the number of sibling elements of <span class="math inline"><em>n</em></span> for which <span class="math inline"><em>s</em></span> returned an element</li>
</ol>
<p>Notice how the row-sibling constraint simplifies the problem: row candidates without siblings that return an element after <span class="math inline"><em>s</em></span> is executed on them have <span class="math inline"><em>n</em><sub><em>s</em><em>i</em><em>b</em><em>l</em><em>i</em><em>n</em><em>g</em><em>s</em></sub></span> = 0, thus disqualifying them. Furthermore, a candidate element <span class="math inline"><em>n</em></span> is only accepted as the row element if the row selector associated with it only matches itself and elements that are its direct siblings.</p>
<p>From the parent of the initial SPAN element, the algorithm moves up the DOM tree until it reaches the BODY element. Then, it generates a selector for each <span class="math inline"><em>n</em></span> and discards any <span class="math inline"><em>n</em></span> with a selector that matches elements that are either not itself or a direct sibling. Finally, the algorithm picks an <span class="math inline"><em>n</em></span> with the largest, positive <span class="math inline"><em>n</em><sub><em>s</em><em>i</em><em>b</em><em>l</em><em>i</em><em>n</em><em>g</em><em>s</em></sub></span>, preferring nodes lower in the tree as a tiebreaker. <span class="math inline"><em>s</em></span> is used as the selector for the column.</p>
<p>In the above sample DOM, the first parent element is the DIV with class <em>names</em> when the user clicks on the SPAN element containing “Tony Stark.” This DIV has a sibling SPAN element, but the sibling doesn’t return an element when <em>.super_hero</em>, the selector that identifies the initial SPAN in the DIV, is executed on it. As a result, it has <span class="math inline"><em>n</em><sub><em>s</em><em>i</em><em>b</em><em>l</em><em>i</em><em>n</em><em>g</em><em>s</em></sub></span> = 0. At the level above that, we consider the DIV with class <em>avenger</em>, which has at least one sibling that returns an element when the selector <em>.super_hero</em> is executed on it. Finally, the level above that once again has no siblings that return an element when the selector <em>.super_hero</em> is executed on them. Therefore, our algorithm returns the DIV element and outputs <em>.avenger</em> as the row selector and <em>.super_hero</em> as the column selector. These selectors are used to generate a DOM scraping adapter which returns the DOM elements corresponding to a superhero data row in the table.</p>
<h2 data-number="3.2" id="live-programming"><span class="header-section-number">3.2</span> Live Programming</h2>
<p>Live programming is implemented by continually running the generalization algorithm on the DOM element under the user’s cursor, reverting if the user hovers away and committing when the user clicks. The generated row and column selectors are used to highlight all the matching elements on the website and create an adapter. Highlighting all the matching column elements on the website provides visual feedback about the system’s generalization to the user. Creating an adapter enables the system to populate the table view and set up the bidirectional synchronization. Because the table is populated and the bidirectional synchronization is set up, users can customize as they scrape.</p>
<h2 data-number="3.3" id="editing-by-demonstration"><span class="header-section-number">3.3</span> Editing By Demonstration</h2>
<p>The implementation of the editing by demonstration feature is rather simple. Because users interact with the scraped data directly in the context of the website, it is easy to re-initiate the scraping system. Our system generates adapters with metadata that can be used to boot it up. The metadata simply consists of the row selector and the column selectors. Our generalization algorithm takes the provided row selector and uses it to generate new column selectors. We are keen to explore what other implementations of programming by demonstration this can be done for and what the implications and benefits would be.</p>
<h2 data-number="3.4" id="limitations"><span class="header-section-number">3.4</span> Limitations</h2>
<p>The row-sibling constraint we mentioned earlier is important for the end goal of customization because row elements that are not direct siblings may not represent data on the website that should be related as part of the same table by customizations such as sorting and filtering. Take the following sample HTML layout showing two tables of superheros (Team Iron Man and Team Captain America):</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;h1&gt;</span> Team Iron Man <span class="kw">&lt;/h1&gt;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">’container’</span><span class="kw">&gt;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;avenger&#39;</span><span class="kw">&gt;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>          <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span> Iron Man <span class="kw">&lt;/span&gt;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;/div&gt;</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;avenger&#39;</span><span class="kw">&gt;</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>          <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span>  Black Widow <span class="kw">&lt;/span&gt;</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;/div&gt;</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>      ...</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;/div&gt;</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;h1&gt;</span> Team Captain America <span class="kw">&lt;/h1&gt;</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;div&gt;</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;avenger&#39;</span><span class="kw">&gt;</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>          <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span> Captain America <span class="kw">&lt;/span&gt;</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;/div&gt;</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;div</span><span class="ot"> class=</span><span class="st">&#39;avenger&#39;</span><span class="kw">&gt;</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>          <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span>  Scarlet Witch <span class="kw">&lt;/span&gt;</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>      <span class="kw">&lt;/div&gt;</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>      ...</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;/div&gt;</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span></span></code></pre></div>
<p>Without the constraint that row elements have to be direct siblings, the row generalization algorithm could determine the row selector to be <em>.avenger</em> because it matches the most number of parallel structures (has the largest <span class="math inline"><em>n</em><sub><em>s</em><em>i</em><em>b</em><em>l</em><em>i</em><em>n</em><em>g</em><em>s</em></sub></span>). While this may be the correct result for the task of extraction, it is not for the task of customization. The selector matches all rows across the two tables so the sorting and filtering customizations could place rows in the incorrect table and thereby distort what the tables represent. Because of this, our system currently does not support generalizing over websites with such HTML layouts but we plan to explore the possibility of extracting multiple tables from a website and joining them.</p>
<p>Another HTML layout that our system cannot currently generalize over is one in which column elements are not contained within a row element that is a direct sibling of all the other row elements. Take the following sample HTML layout showing a table of superheros:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;h1</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span> Iron Man <span class="kw">&lt;/h1&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;real_name&#39;</span><span class="kw">&gt;</span> Real Name: Tony Stark <span class="kw">&lt;/span&gt;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;h1</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span> Captain America <span class="kw">&lt;/h1&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;real_name&#39;</span><span class="kw">&gt;</span> Real Name: Steven Rogers <span class="kw">&lt;/span&gt;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;h1</span><span class="ot"> class=</span><span class="st">&#39;super_hero_name&#39;</span><span class="kw">&gt;</span> Black Widow <span class="kw">&lt;/h1&gt;</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;span</span><span class="ot"> class=</span><span class="st">&#39;real_name&#39;</span><span class="kw">&gt;</span> Real Name: Natalia Romanoff <span class="kw">&lt;/span&gt;</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  ...</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span></span></code></pre></div>
<p>The HTML contains one table of data in which rows are made up of an H1 tag (super hero name) and a SPAN tag (real name). For the task of extraction, the DOM elements can be scraped using the shown classes to output a table in which the values of the H1 tags form the first column and the values of the SPAN tag form the second column. For the task of customization, our system would need to know what the row boundaries are in order for customizations such as sorting and filtering to not distort the representation of the website. This can be done in adapters written by a programmer by creating artificial row boundaries. In the above DOM structure, an artificial row boundary could be created by representing a row as an H1 tag and the SPAN tag that immediately follows it. These artificial rows would form a single unit which would not distort the website after a sorting or filtering customization. We plan to explore how artificial row boundaries can be created via demonstration in order to support such DOM structures which are not uncommon (HackerNews has this type of DOM structure).</p>
<h1 data-number="4" id="sec:design-principles"><span class="header-section-number">4</span> Design Principles</h1>
<p>Below, we discuss the design principles underlying our work.</p>
<h2 data-number="4.1" id="unified-environment"><span class="header-section-number">4.1</span> Unified Environment</h2>
<p>In the previous iteration of Wildcard, web scraping was an entirely separate activity from customization. Programmers that wrote scraping adapters would need to switch into an IDE to write code as part of customizing a new website, making it a much less unified environment. This type of divide between tasks appears in other tools and is undesirable to users. The creators of Wrex <span class="citation" data-cites="drosos2020">[<a href="#ref-drosos2020" role="doc-biblioref">5</a>]</span>, a programming-by-example system for data wrangling, reported that “although data scientists were aware of and appreciated the producitivy benefits of existing data wrangling tools, having to leave their native notebook environment to perform wrangling limited the usefulness of these tools.”</p>
<p>In the domain of web scraping, scraper creation is treated as a specialized step, distinct from other stages of work. The scraped data is exported to a database or a spreadsheet for further processing: if the user comes across an omission or a problem while working with the data, they need to switch environments to edit the scraping logic. The problem also emerges in web customization tools more similar to Wildcard, like Vegemite <span class="citation" data-cites="lin2009">[<a href="#ref-lin2009" role="doc-biblioref">11</a>]</span>, which had separate steps for selecting and augmenting data. In a user study of Vegemite, participants reported that “it was confusing to use one technique to create the initial table, and another technique to add information to a new column.’”</p>
<p>In this work, we have combined scraping and customization into a unified activity within a single environment. The goal is to minimize the environment switch between <em>extracting</em> the data and <em>using</em> the data. A user might start out by scraping some data, and then switch to customizing the website using the results. Then, they might realize they need more data to perform their desired task, at which point they can easily augment the adapter by demonstrating new columns. All of these tasks take place right in the browser, where the user was initially already using the uncustomized website. Instead of bringing the data to another tool, we have brought a tool to the data.</p>
<p>Of course, there is value in specialized tools: Wildcard has nowhere near the full capabilities of spreadsheet software or databases. Nevertheless, we believe a unified environment for scraping and customization presents a significantly lower barrier to entry for customization.</p>
<h2 data-number="4.2" id="editing-by-demonstration-1"><span class="header-section-number">4.2</span> Editing By Demonstration</h2>
<p>Many end-user web scraping and macro systems allow users to create programs by demonstration but do not offer a way to edit them by demonstration. In Rousillon <span class="citation" data-cites="chasins2018">[<a href="#ref-chasins2018" role="doc-biblioref">4</a>]</span>, a web scraping program created by demonstration can only be edited through a high-level, block-based programming language. In Vegemite <span class="citation" data-cites="lin2009">[<a href="#ref-lin2009" role="doc-biblioref">11</a>]</span>, an automation program created through demonstration can only be edited by editing the text-based representation of the program.</p>
<p>In Wildcard, if a website’s adapter ceases to function because the website changes, the table may lose its data which means that an end-user’s customizations may also cease to function. Furthermore, end-users are powerless to extend the scraping adapter to add columns to the table in order to perform new customizations. This goes against MacLean et. al.’s vision of user-tailarable systems <span class="citation" data-cites="maclean1990">[<a href="#ref-maclean1990" role="doc-biblioref">13</a>]</span> that give users “a feeling of ownership of the system, to feel in control of changing the system and to understand what can be changed.” Providing an easy way for users to edit programs is therefore fundamental to fully democratizing web customization.</p>
<p>Editing by demonstration promises to make end-users first-class citizens in the customization ecosystem. Because users interact with the scraped data directly in the context of the website, it is easy to re-initiate the scraping system. The edit process simply boots up the scraping system using metadata stored with the scraping adapter to the state when the demonstration was completed. Users that have gone through the creation process will immediately realize what to do in order to extend or repair the adapter. Users that have not gone through the creation process might have a harder time but we provide visual clues (such as highlighting the row to perform demonstrations from with a green border) and live programming (immediately preview the results of demonstrations) that serve as guides.</p>
<p>Editing by demonstration in the web scraping domain is feasible because the programs that scrape column values are independent of each other: changing the program that scrapes values into column A has no effect on the program that scrapes values in column B. However, changing the program that retrieves rows would affect the programs that scrape values into columns because they are dependent on the values being available in a row. This is therefore not supported but is an acceptable limitation for us given our focus on extension and repair which only deal with programs that scrape column values.</p>
<p>This design principle is related to the idea of “in-place toolchains” <span class="citation" data-cites="zotero-60">[<a href="#ref-zotero-60" role="doc-biblioref">2</a>]</span> being an integral part of end-user programming systems. The authors champion the practice of end-user programming systems allowing users to edit programs “using an interface and set of abstractions that is as close as possible to the ones they use for their regular daily work.”</p>
<h2 data-number="4.3" id="live-programming-1"><span class="header-section-number">4.3</span> Live Programming</h2>
<p>In some end-user web scraping systems like Rousillon <span class="citation" data-cites="chasins2018">[<a href="#ref-chasins2018" role="doc-biblioref">4</a>]</span>, users only get <em>full</em> feedback about the program’s execution (generalization and the scraped values) after providing all the demonstrations. This means they cannot adjust their demonstrations in response to the system’s feedback as they demonstrate.</p>
<p>Our end-user web scraping system employs live programming techniques to eliminate this edit-compile-debug cycle by running the generalization algorithm and generating an adapter after each user demonstration. As we show in Section 2, when a user demonstrates a value of a column they wish to scrape, our system immediately shows how it has generalized the user’s demonstration across the other rows of the data by highlighting the all relevant values. It also populates the table with the scraped data based on the latest demonstration. The highlighting and table population serve to give users a view of how their demonstration has been generalized and what data will be available in the table once scraped.</p>
<p>This live programming environment is similar to that of FlashProg <span class="citation" data-cites="mayer2015">[<a href="#ref-mayer2015" role="doc-biblioref">14</a>]</span>, a framework that provides user interface support for programming-by-demonstration systems like FlashExtract <span class="citation" data-cites="le2014">[<a href="#ref-le2014" role="doc-biblioref">9</a>]</span>, and relates to the idea that an important quality of end-user programming is “interaction with a living system” <span class="citation" data-cites="zotero-60">[<a href="#ref-zotero-60" role="doc-biblioref">2</a>]</span>. Hugely successful end-user programming systems such as spreadsheets and SQL provide users immediate results after entering commands. Unlike text-based commands which are only valid when complete (e.g <code>SELECT * FRO</code> vs <code>SELECT * FROM user_table</code>), the target of demonstration commands (value of DOM element under the cursor) is the same during both hover and click (incomplete command vs complete command). This allows us to take a small step further by executing a command before a user completes it, thereby providing them with a preview of the results on hover.</p>
<p>There are limits to this approach. Providing live feedback on websites with a large number of DOM elements or complex CSS selectors can slow down the generalization process, especially if a user is constantly moving their cursor. Furthermore, many datasets are too large to entirely preview in the table; the user might benefit more from the live feedback if it could summarize large datasets. For example, FlashProg provides a summary of the generalization through a color-coded minimap next to the scrollbar of its extraction interface.</p>
<h1 data-number="5" id="sec:related-work"><span class="header-section-number">5</span> Related Work</h1>
<p>End-user web scraping for customization relates to existing work in end-user web scraping by a number of tools.</p>
<p>FlashProg <span class="citation" data-cites="mayer2015">[<a href="#ref-mayer2015" role="doc-biblioref">14</a>]</span> is a framework that provides user interface support for FlashExtract <span class="citation" data-cites="le2014">[<a href="#ref-le2014" role="doc-biblioref">9</a>]</span>, a framework for data scraping by examples. FlashProg’s interface provides immediate visual feedback about the generalization and scrapes the matched values in an output tab. In addition, it has a program viewer tab that contains a high level description of what the generated program is doing and provides a list of alternative programs. Finally, it has a disambiguation tab that utilizes conversational clarification to disambiguate programs, the conservations with the user serving as inputs to generate better programs. Though FlashProg has many desirable features we aim to implement in future iterations, it does not offer a unified environment within a browser for scraping and customizing websites.</p>
<p>Roussillon <span class="citation" data-cites="chasins2018">[<a href="#ref-chasins2018" role="doc-biblioref">4</a>]</span> is a tool that enables end-users to scrape distributed, hierarchical web data. Its interface does not provide <em>full</em> live feedback about its generalizations or the values to be scrapped until all the demonstrations have been provided and the generated program has been run. If run on a website it has encountered before, Roussillon makes all the previously determined generalizations visible to the user by color-coding the values on the website that belong to the same column. This is a desirable feature for our system as users will not have to actively explore in order to discover which values are available for scraping and how they are related to each other. On the extension and repair front, Roussillon presents the web scraping code generated by demonstration as an editable, high-level, block-based language called Helena <span class="citation" data-cites="zotero-51">[<a href="#ref-zotero-51" role="doc-biblioref">1</a>]</span>. While Helena can be used to perform more complex editing tasks like adding control flow, it presents a change in the model used for creation. Our system maintains the model used for creation by allowing users to extend and repair web scraping code via demonstration.</p>
<p>Vegemite <span class="citation" data-cites="lin2009">[<a href="#ref-lin2009" role="doc-biblioref">11</a>]</span> is a tool for end-user programming of mashups. It has two interfaces: one for scraping values from a website and another for creating scripts that operate on the scraped values. The web scraping interface does not provide live feedback about the generalization on hover but after a user clicks, the interface shows the result of the system’s generalization by highlighting the all matched values. Furthermore, even though the interface also has a table, the table is only populated with the scraped values after all the demonstrations have been provided. The scripting interface utilizes CoScripter <span class="citation" data-cites="leshed2008">[<a href="#ref-leshed2008" role="doc-biblioref">10</a>]</span> which is used to record operations on the scraped values for automation. For example, the scripting interface can be used to demonstrate the task of copying an address in the table, pasting it into a walk score calculator and pasting the result back into the table. The script would then be generalized to all the rows and re-run to fill in the remaining walk scores. CoScripter provides the generated automation program as text-based commands, such as “paste address into ‘Walk Score’ input,” which can be edited after the program is created via “sloppy programming” <span class="citation" data-cites="lin2009">[<a href="#ref-lin2009" role="doc-biblioref">11</a>]</span> techniques. However, this editing does not extend to the web scraping interface used for demonstrations.</p>
<p>Sifter <span class="citation" data-cites="huynh2006">[<a href="#ref-huynh2006" role="doc-biblioref">7</a>]</span> is a tool that augments well structured websites with advanced sorting and filtering functionality. Like Wildcard, it uses web scraping to extract data from websites in order to enable customizations (sorting and filtering). It performs the web scraping automatically using a variety of heuristics and solicits guidance from the user if this fails. While automatic web scraping seems desirable, it is unclear how useful it is if the goal is customization. Given a row with ten scrapable values, and therefore ten columns, would a user prefer to simply demonstrate the value for the single column they are interested in or un-demonstrate the nine values they are not interested in? This is a question we can only answer after performing a user study.</p>
<h1 data-number="6" id="sec:conclusion"><span class="header-section-number">6</span> Conclusion And Future Work</h1>
<p>In this paper, we presented our progress towards end-user web scraping for customization to empower end-users in Wildcard’s ecosystem to create, extend and repair scraping adapters. There are several outstanding issues and open questions we hope to address in future work.</p>
<p>Like existing approaches, web scraping in our current implementation is limited to what can be demonstrated. This is problematic if users want to scrape the URL associated with a link element, which is not visible, or only scrape a substring of a value. To solve this, we plan to harness Wildcard’s formula language. Motivated end-users will able to use formulas targeted at web scraping, for example <code>=GetAttribute(link_column, ‘href’)</code>, and formulas targeted at value processing, for example <code>=GetSubstring(amount_column, 1, 2)</code>, to scrape the URL associated with columns whose values are scraped from link elements and the substring of values associated with columns whose values are strings respectively. This will give end-users some of the power available to programmers that write web scraping code in Javascript which supports a wide variety of DOM access and processing ability.</p>
<p>To verify our design principles, we plan to carry out a broader evaluation of our system through a user study. Furthermore, we plan to incorporate the program viewer and disambiguation features available in FlashProg <span class="citation" data-cites="mayer2015">[<a href="#ref-mayer2015" role="doc-biblioref">14</a>]</span> to give users more insight and control into the generalization process as well as a more concrete alternative, than providing further demonstrations, to aid the generalization through disambiguation. One question we aim to ponder is whether formulas, which are in essence programs, are self-descriptive enough to not warrant paraphrasing in English as is the case with FlashExtract’s <span class="citation" data-cites="le2014">[<a href="#ref-le2014" role="doc-biblioref">9</a>]</span> C# programs.</p>
<p>Our end goal is to empower end-users to customize websites with full control of the various aspects that are needed to enable the customizations. This in turn will help make the malleability of the web a reality for all of its users.</p>
<h1 class="unnumbered" id="bibliography">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-zotero-51" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Helena | <span>Web Automation</span> for <span>End Users</span>. Retrieved February 12, 2021 from <a href="http://helena-lang.org/">http://helena-lang.org/</a></div>
</div>
<div id="ref-zotero-60" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">End-user programming. Retrieved February 12, 2021 from <a href="https://www.inkandswitch.com/end-user-programming.html">https://www.inkandswitch.com/end-user-programming.html</a></div>
</div>
<div id="ref-bolin2005" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Michael Bolin, Matthew Webber, Philip Rha, Tom Wilson, and Robert C. Miller. 2005. Automation and customization of rendered web pages. In <em>Proceedings of the 18th annual <span>ACM</span> symposium on <span>User</span> interface software and technology - <span>UIST</span> ’05</em>, <span>ACM Press</span>, <span>Seattle, WA, USA</span>, 163. DOI:https://doi.org/<a href="https://doi.org/10.1145/1095034.1095062">10.1145/1095034.1095062</a></div>
</div>
<div id="ref-chasins2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Sarah E. Chasins, Maria Mueller, and Rastislav Bodik. 2018. Rousillon: <span>Scraping Distributed Hierarchical Web Data</span>. In <em>The 31st <span>Annual ACM Symposium</span> on <span>User Interface Software</span> and <span>Technology</span> - <span>UIST</span> ’18</em>, <span>ACM Press</span>, <span>Berlin, Germany</span>, 963–975. DOI:https://doi.org/<a href="https://doi.org/10.1145/3242587.3242661">10.1145/3242587.3242661</a></div>
</div>
<div id="ref-drosos2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Ian Drosos, Titus Barik, Philip J. Guo, Robert DeLine, and Sumit Gulwani. 2020. Wrex: <span>A Unified Programming</span>-by-<span>Example Interaction</span> for <span>Synthesizing Readable Code</span> for <span>Data Scientists</span>. In <em>Proceedings of the 2020 <span>CHI Conference</span> on <span>Human Factors</span> in <span>Computing Systems</span></em>, <span>ACM</span>, <span>Honolulu HI USA</span>, 1–12. DOI:https://doi.org/<a href="https://doi.org/10.1145/3313831.3376442">10.1145/3313831.3376442</a></div>
</div>
<div id="ref-hogue2005" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Andrew Hogue and David Karger. 2005. Thresher: Automating the unwrapping of semantic content from the <span>World Wide Web</span>. In <em>Proceedings of the 14th international conference on <span>World Wide Web</span> - <span>WWW</span> ’05</em>, <span>ACM Press</span>, <span>Chiba, Japan</span>, 86. DOI:https://doi.org/<a href="https://doi.org/10.1145/1060745.1060762">10.1145/1060745.1060762</a></div>
</div>
<div id="ref-huynh2006" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">David F. Huynh, Robert C. Miller, and David R. Karger. 2006. Enabling web browsers to augment web sites’ filtering and sorting functionalities. In <em>Proceedings of the 19th annual <span>ACM</span> symposium on <span>User</span> interface software and technology - <span>UIST</span> ’06</em>, <span>ACM Press</span>, <span>Montreux, Switzerland</span>, 125. DOI:https://doi.org/<a href="https://doi.org/10.1145/1166253.1166274">10.1145/1166253.1166274</a></div>
</div>
<div id="ref-kushmerick2000" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Nicholas Kushmerick. 2000. Wrapper induction: <span>Efficiency</span> and expressiveness. <em>Artificial Intelligence</em> 118, 1 (April 2000), 15–68. DOI:https://doi.org/<a href="https://doi.org/10.1016/S0004-3702(99)00100-9">10.1016/S0004-3702(99)00100-9</a></div>
</div>
<div id="ref-le2014" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Vu Le and Sumit Gulwani. 2014. <span>FlashExtract</span>: A framework for data extraction by examples. In <em>Proceedings of the 35th <span>ACM SIGPLAN Conference</span> on <span>Programming Language Design</span> and <span>Implementation</span></em>, <span>ACM</span>, <span>Edinburgh United Kingdom</span>, 542–553. DOI:https://doi.org/<a href="https://doi.org/10.1145/2594291.2594333">10.1145/2594291.2594333</a></div>
</div>
<div id="ref-leshed2008" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">Gilly Leshed, Eben M. Haber, Tara Matthews, and Tessa Lau. 2008. <span>CoScripter</span>: Automating &amp;amp; sharing how-to knowledge in the enterprise. In <em>Proceedings of the <span>SIGCHI Conference</span> on <span>Human Factors</span> in <span>Computing Systems</span></em> (<span>CHI</span> ’08), <span>Association for Computing Machinery</span>, <span>New York, NY, USA</span>, 1719–1728. DOI:https://doi.org/<a href="https://doi.org/10.1145/1357054.1357323">10.1145/1357054.1357323</a></div>
</div>
<div id="ref-lin2009" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">James Lin, Jeffrey Wong, Jeffrey Nichols, Allen Cypher, and Tessa A. Lau. 2009. End-user programming of mashups with vegemite. In <em>Proceedings of the 14th international conference on <span>Intelligent</span> user interfaces</em> (<span>IUI</span> ’09), <span>Association for Computing Machinery</span>, <span>New York, NY, USA</span>, 97–106. DOI:https://doi.org/<a href="https://doi.org/10.1145/1502650.1502667">10.1145/1502650.1502667</a></div>
</div>
<div id="ref-litt2020a" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">Geoffrey Litt and Daniel Jackson. 2020. Wildcard: <span>Spreadsheet</span>-<span>Driven Customization</span> of <span>Web Applications</span>. In <em>Companion <span>Proceedings</span> of the 4th <span>International Conference</span> on the <span>Art</span>, <span>Science</span>, and <span>Engineering</span> of <span>Programming</span></em>, <span>Association for Computing Machinery</span>, <span>Porto, Portugal.</span>, 10. DOI:https://doi.org/<a href="https://doi.org/10.1145/3397537.3397541">10.1145/3397537.3397541</a></div>
</div>
<div id="ref-maclean1990" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">Allan MacLean, Kathleen Carter, Lennart Lövstrand, and Thomas Moran. 1990. User-tailorable systems: Pressing the issues with buttons. In <em>Proceedings of the <span>SIGCHI Conference</span> on <span>Human Factors</span> in <span>Computing Systems</span></em> (<span>CHI</span> ’90), <span>Association for Computing Machinery</span>, <span>New York, NY, USA</span>, 175–182. DOI:https://doi.org/<a href="https://doi.org/10.1145/97243.97271">10.1145/97243.97271</a></div>
</div>
<div id="ref-mayer2015" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">Mikaël Mayer, Gustavo Soares, Maxim Grechkin, Vu Le, Mark Marron, Oleksandr Polozov, Rishabh Singh, Benjamin Zorn, and Sumit Gulwani. 2015. User <span>Interaction Models</span> for <span>Disambiguation</span> in <span>Programming</span> by <span>Example</span>. In <em>Proceedings of the 28th <span>Annual ACM Symposium</span> on <span>User Interface Software</span> &amp; <span>Technology</span></em>, <span>ACM</span>, <span>Charlotte NC USA</span>, 291–301. DOI:https://doi.org/<a href="https://doi.org/10.1145/2807442.2807459">10.1145/2807442.2807459</a></div>
</div>
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-38867184-1', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
